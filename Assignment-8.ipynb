{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c376fae",
   "metadata": {},
   "source": [
    "1.What exactly is a feature? Give an example to illustrate your point?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e655b20",
   "metadata": {},
   "source": [
    "Ans: Feature are the basic building blocks of datasets.The quality of the feature in your dataset has a major impact on the quality of the insights you will gain when you use dataset for machine learning.\n",
    "\n",
    "Additionally,different bussiness problem within the same industry do not necessarily require the same feature, which is why it is important to have strong understanding of the dussiness goals of your datascience project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488335dc",
   "metadata": {},
   "source": [
    "2.What are the various circumstances in which feature construction is required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5927e4",
   "metadata": {},
   "source": [
    "Ans:The features in your data will directly influence the predictive models you use and the results you can achieve. your result are dependent on many inter-dependent properties.You need a great feature that describe the structure inherent in your data.Better feature means flexibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e723310",
   "metadata": {},
   "source": [
    "3.Describe how nominal variables are encoded?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a9ad5",
   "metadata": {},
   "source": [
    "Ans:Nominal data is made of discrete values with no numerical relationship between the different categories -- mean and median are meaningless.Animal species is one example.\n",
    "pig is not higher than bird and lower than fish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e0d7a",
   "metadata": {},
   "source": [
    "4.Describe how numeric features are converted to categorical features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003cc94d",
   "metadata": {},
   "source": [
    "Ans: Converting categorical feature inot numerical feature using domain knowledge.For example, we are given a list of countries and say we know the distance to these countries from India then we can replace it with distance from India.So, every country can represented as its distance from India."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa71eedb",
   "metadata": {},
   "source": [
    "5.Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b05db",
   "metadata": {},
   "source": [
    "Ans:Wrapper methods measure the usefulness of feature based on the classifier performance. In contrast the filter methods pick up the intrinsic properties of the features i.e the \"relevance\" of the features measured via univariate statistics instead of cross validation performance.\n",
    "\n",
    "The wrapper classification algorithm with joint dimensionality reduction and classification can also be used but these methods have high computation cost,loe=wer discriminative power.Moreover these methods depends on the efficient selection of classifiers for obtanining high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae8651",
   "metadata": {},
   "source": [
    "6.When is a feature considered irrelevant? What can be said to quantify it ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05727fe9",
   "metadata": {},
   "source": [
    "Feature are considered relevant if they are either strongly or weakely relevant, and are considered irrelevant otherwise.\n",
    "\n",
    "Irrelevant feature can never contribute to prediction accuracy, by definition. Also to quantify it we need ti first check the list of features, \n",
    "\n",
    "There are three types of feature selection:\n",
    "\n",
    "1.Wrapper methods\n",
    "\n",
    "2.Filter methods\n",
    "\n",
    "3.Embedded methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba24673",
   "metadata": {},
   "source": [
    "7.When is a function considered redundant? What criteria are used to identify features that could be redundant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655da4cf",
   "metadata": {},
   "source": [
    "Ans:I ftwo features {X1,X2} are highly correleated , then the two features become redundant features since they have same information in terms of correleation measure. In other words, the correlation measure provides statistical association between any given a pairs of features.\n",
    "\n",
    "Minimum redundancy feature selection is an algorithm frequently used in a method to accrately identify characteristics of genes snd phenotypes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08eb53a",
   "metadata": {},
   "source": [
    "8.What are the various distance measurements used to determine feature similarity ?\n",
    "\n",
    "Ans: Four of the most commonly used distance measures in machine learning are as follows:\n",
    "\n",
    "Hamming Distance.\n",
    "\n",
    "Euclidean Distance\n",
    "\n",
    "Manhattan Distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb9d9a",
   "metadata": {},
   "source": [
    "9.State difference between Euclidean and Manhattan distances ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568528b",
   "metadata": {},
   "source": [
    "Euclidean and hamming distance are used to measure similarity or dissimilarity between two sequneces. Euclidean distance is extensively appled in analysis of convolutional codes and Trellis codes.\n",
    "\n",
    "Hamming distance is frequently encountered in the analysis of block code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff842c2d",
   "metadata": {},
   "source": [
    "10.Distinguish between feature transformation and feature selection ?\n",
    "\n",
    "Ans: Feature selection is for filtering irrelevant or redundant features from your dataset. The key difference between feature selection and extraction is that feature selection keeps a subset of the original features while feature extraction creates brand new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4061720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
